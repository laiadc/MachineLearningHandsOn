{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2fdBzI62UQr"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/laiadc/MachineLearningHandsOn/blob/main/day4/Deep%20learning%20for%20image%20recognition.ipynb)\n",
    "\n",
    "# How to learn Deep Learning models?\n",
    "\n",
    "We have seen that deep learning models consist of a set of layers of neurons with connections between the nodes of each layer. Each layer *learns* a particular feature or trait of the input and uses it to predict the output. \n",
    "\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1X3iQfNGN10ZPUak_M4BrjRZKzS8mg0DU)\n",
    "\n",
    "+ What do we want the neural network to learn? Given the image input (e.g the hand-written number five), we want to learn to **predict the label** (e.g 5). \n",
    "\n",
    "+ What do we have to learn to train the neural network? The **connection weights** $w_{11}, w_{12}, \\cdots w_{NK}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65FN2Bos9hmw"
   },
   "source": [
    "## Elements for training\n",
    "\n",
    "Even though the algoritm to train the network is quite complex, there are python libraries which make it easy for us to train a neural network. There are just a few things we have to specify, and the library will do the rest:\n",
    "\n",
    "+ The number of hidden layers.\n",
    "\n",
    "+ The number of neurons for each layer\n",
    "\n",
    "+ The type of layer: There are several modifications of the standard neural network described above. These modifications are often used for specific purposes:\n",
    "  + Fully-connected layer: It is the classical layer, used for general applications.\n",
    "  + Convolutional layer: Mostly used when the input of the network is an image.\n",
    "  + Recurrent layer: Used for time series prediction.\n",
    "  + ...\n",
    "\n",
    "+ The number of epochs: This is the number of iterations used to train the network. The higher the number of epochs, the longer the training time. \n",
    "\n",
    "+  The **loss function**: The loss function is the function the neural network will try to optimize. It should represent the error that the network commits at predicting. For example, if we are performing classification, we will want the loss function to be zero when the prediction is correct, and higher than zero when the prediction is incorrect. That is\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) =  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 & \\text{if } y=\\hat{y}\\\\\n",
    "      1 & \\text{if } y\\neq\\hat{y}\n",
    "\\end{array} \n",
    "\\right. \n",
    "$$\n",
    "\n",
    "However, this loss function is not a continuous function and therefore it is not suitable for the learning algoritm (it computes the derivatives of the loss function). For this reason, for classification tasks we use a loss function called **cross-entropy**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\sum_i t_i \\log(s_i) \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "t_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 & \\text{if } y=\\hat{y}\\\\\n",
    "      1 & \\text{if } y\\neq\\hat{y}\n",
    "\\end{array} \n",
    "\\right. \n",
    "$$\n",
    "\n",
    "and $s_i$ is the probablity predicted by the model of $\\hat{y}$ being $y$. \n",
    "\n",
    "+ There are other parameters which are used in the training algorithm. To enumerate some of them: the learning rate, the batch size, the optimizer, activation function... you can look for information about all these parameters. In this example we will use the standard parameters, which are given by default. \n",
    "\n",
    "\n",
    "The training algorithm will do as follows:\n",
    "\n",
    "+ Initialize the model parameters (weights) to some values.\n",
    "+ Read the training data (for each example).\n",
    "+ Predict the output with the current parameters.\n",
    "+ Compute the loss.\n",
    "+ Adjuts the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8upSBomAEtEN"
   },
   "source": [
    "# Neural Networks for image recognition\n",
    "\n",
    "Let's classify handwritten digits:\n",
    "\n",
    "![alt text](https://github.com/DataScienceUB/DeepLearningMaster20192020/blob/master/images/mnistExamples.png?raw=1)\n",
    "\n",
    "The next cell imports the digits dataset and show some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "executionInfo": {
     "elapsed": 3617,
     "status": "ok",
     "timestamp": 1620647891856,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "yrjgcKgAxbuA",
    "outputId": "f5ec8202-024e-434a-e3b8-f6de5fbdaae5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  5           0             4            1             9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "fig, ax = plt.subplots(1,5,figsize=(10, 10))\n",
    "for i in range(5):\n",
    "  ax[i].imshow(X_train[i].reshape((28, 28)), interpolation='nearest', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Labels: {:2}  {:10} {:13} {:12}  {:12}\".format(y_train[0],y_train[1],y_train[2],y_train[3],y_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3613,
     "status": "ok",
     "timestamp": 1620647891859,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "hDxZzJeZDN-m",
    "outputId": "0e3b5c84-7e13-4cb1-a41a-eb94e7ceb0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set:  60000\n",
      "Size of the test set:  10000\n"
     ]
    }
   ],
   "source": [
    "print('Size of the training set: ', X_train.shape[0])\n",
    "print('Size of the test set: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BLBwj9zDXS0"
   },
   "source": [
    "As we can see, we need a lot of data to train these kind of models. \n",
    "\n",
    "Now we will how to define and train a neural network using a library called Keras.  We will begin using a standard **fully-connected network**.\n",
    "\n",
    "First of all, let us define the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:48:01.408944Z",
     "start_time": "2019-03-05T11:48:01.370766Z"
    },
    "executionInfo": {
     "elapsed": 3610,
     "status": "ok",
     "timestamp": 1620647891862,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "LNUN3agUEtEP"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input    = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes  = 10  # MNIST total classes (0-9 digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:48:03.287003Z",
     "start_time": "2019-03-05T11:48:03.281960Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4003,
     "status": "ok",
     "timestamp": 1620647892259,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "qGufCkh1EtER",
    "outputId": "12f0fa9d-6f28-4e20-a7d7-3e3f099a58ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Adds a fully-connected layer with 256 units to the model:\n",
    "model.add(layers.Dense(n_hidden_1, activation='relu', input_shape=(n_input,)))\n",
    "\n",
    "# Add another:\n",
    "model.add(layers.Dense(n_hidden_2, activation='relu'))\n",
    "\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnV9039jFNhs"
   },
   "source": [
    "The function .summary() shows the internal structure of the network. Now that we have designd the network, we choose the loss function that will be used to train the model. In this case, we use the cross-entropy loss. In order to specify the loss function, we use the function .compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:48:05.138426Z",
     "start_time": "2019-03-05T11:48:05.014267Z"
    },
    "executionInfo": {
     "elapsed": 4003,
     "status": "ok",
     "timestamp": 1620647892263,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "lQ26w2IQEtES"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUVSlk43FwK-"
   },
   "source": [
    "Finally, we need to train the model. We use the function .fit() to do so. First, we need to prepare the data for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1620647930961,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "4_w-sM8rG4hS"
   },
   "outputs": [],
   "source": [
    "# Prepare the data to give it to the NN\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train_NN = enc.fit_transform(y_train.reshape(-1,1))\n",
    "X_train_NN = X_train.reshape(-1, 28*28)\n",
    "\n",
    "y_test_NN = enc.transform(y_test.reshape(-1,1))\n",
    "X_test_NN = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T11:48:26.092599Z",
     "start_time": "2019-03-05T11:48:05.858881Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103927,
     "status": "ok",
     "timestamp": 1620648035740,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "9ymMFktxEtEU",
    "outputId": "66b2f4e1-2fb4-43e0-dac3-0f890f760d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 4.8384 - accuracy: 0.8494 - val_loss: 0.4483 - val_accuracy: 0.9338\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3263 - accuracy: 0.9439 - val_loss: 0.2652 - val_accuracy: 0.9441\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1598 - accuracy: 0.9613 - val_loss: 0.2488 - val_accuracy: 0.9471\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1164 - accuracy: 0.9693 - val_loss: 0.2090 - val_accuracy: 0.9497\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1078 - accuracy: 0.9697 - val_loss: 0.1970 - val_accuracy: 0.9570\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1031 - accuracy: 0.9721 - val_loss: 0.1741 - val_accuracy: 0.9603\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1059 - accuracy: 0.9723 - val_loss: 0.1485 - val_accuracy: 0.9647\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0816 - accuracy: 0.9760 - val_loss: 0.1480 - val_accuracy: 0.9641\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0833 - accuracy: 0.9765 - val_loss: 0.1799 - val_accuracy: 0.9619\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0824 - accuracy: 0.9771 - val_loss: 0.1602 - val_accuracy: 0.9632\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0805 - accuracy: 0.9797 - val_loss: 0.1380 - val_accuracy: 0.9715\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0725 - accuracy: 0.9799 - val_loss: 0.1425 - val_accuracy: 0.9724\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0614 - accuracy: 0.9830 - val_loss: 0.1389 - val_accuracy: 0.9715\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0681 - accuracy: 0.9829 - val_loss: 0.1658 - val_accuracy: 0.9664\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0619 - accuracy: 0.9836 - val_loss: 0.1646 - val_accuracy: 0.9694\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0579 - accuracy: 0.9848 - val_loss: 0.1418 - val_accuracy: 0.9724\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0550 - accuracy: 0.9855 - val_loss: 0.1687 - val_accuracy: 0.9715\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0468 - accuracy: 0.9881 - val_loss: 0.1837 - val_accuracy: 0.9724\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0471 - accuracy: 0.9878 - val_loss: 0.1750 - val_accuracy: 0.9724\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0557 - accuracy: 0.9872 - val_loss: 0.1834 - val_accuracy: 0.9737\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0438 - accuracy: 0.9891 - val_loss: 0.1590 - val_accuracy: 0.9739\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0392 - accuracy: 0.9897 - val_loss: 0.2065 - val_accuracy: 0.9749\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0617 - accuracy: 0.9874 - val_loss: 0.2055 - val_accuracy: 0.9722\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 0.2099 - val_accuracy: 0.9721\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0486 - accuracy: 0.9889 - val_loss: 0.2294 - val_accuracy: 0.9714\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0371 - accuracy: 0.9916 - val_loss: 0.1949 - val_accuracy: 0.9740\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0364 - accuracy: 0.9917 - val_loss: 0.2646 - val_accuracy: 0.9695\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0465 - accuracy: 0.9900 - val_loss: 0.2088 - val_accuracy: 0.9747\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0389 - accuracy: 0.9915 - val_loss: 0.2524 - val_accuracy: 0.9742\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.2321 - val_accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f806f70d650>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_NN, y_train_NN, epochs=training_epochs, batch_size=batch_size,\n",
    "          validation_data=(X_test_NN, y_test_NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yk0BIRyqJha4"
   },
   "source": [
    "Finally, we evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1806,
     "status": "ok",
     "timestamp": 1620648074666,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "bi9nNa50EtEX",
    "outputId": "3b8ef389-a9db-4ac6-df26-307750571805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss function: 0.23208358883857727\n",
      "Test accuracy: 0.9700999855995178\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_NN, y_test_NN, verbose=0)\n",
    "\n",
    "print('Test loss function:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuRtpJyRps5k"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Try changing some of the parameters of the neural network and see if it changes the final performance. Remeber that you can change the number of hidden layers, the number of neurons in each layer, the learning rate, the number of epochs and the type of layers (among others). I propose to change the fully-connected layers by convolutional layers. The structure of a convolutional neural network is the following:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1GzbzebrFQ5qkYAcCAIgoOu46g0ruMBgr)\n",
    "\n",
    "The input layer is followed by pairs of convolutional layers and max-pooling layers. The convolutional layers try to extract local patterns of the image. The max-pooling layers try to reduce the dimensionality of the image. After these convolutional and max-pooling layers, the output is passed to a Flatten layer and then to a fully-connected layer. Finally, another fully-connected layer returns the output. Check the following links:\n",
    "\n",
    "+ [Convolutional layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "\n",
    "+ [Max-pooling layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "\n",
    "+ [Flatten layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
    "\n",
    "+ [Fully-connected layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Adds a convolutional layer with 64 units to the model:\n",
    "model.add(layers.Conv2D(64, 3, strides=(2,2), activation='relu',\n",
    "                        input_shape=(28,28,1)))\n",
    "# Add a max-pooling layer:\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "#####################################################\n",
    "# Your code\n",
    "# Add another convolutional layer with 32 neurons and a max-pooling layer\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "# Add a flatten layer\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#####################################################\n",
    "# Your code\n",
    "# Add a fully-connected (Dense) layer with 32 neurons\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "# Add a fully-conencted layer to report the output\n",
    "model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN = X_train.reshape(-1, 28,28,1)\n",
    "X_test_CNN = X_test.reshape(-1, 28,28,1)\n",
    "model.fit(X_train_CNN, y_train_NN, epochs=training_epochs, batch_size=batch_size,\n",
    "          validation_data=(X_test_CNN, y_test_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test_CNN, y_test_NN, verbose=0)\n",
    "\n",
    "print('Test loss function:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep learning for image recognition.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/DataScienceUB/DeepLearningMaster20192020/blob/master/4.%20Tensorflow%20first%20learning%20models.ipynb",
     "timestamp": 1620641208725
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
